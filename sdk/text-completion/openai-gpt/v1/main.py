from enum import Enum
from typing import Optional

import openai
from pydantic import Field

from hyko_sdk.function import SDKFunction
from hyko_sdk.metadata import CoreModel

func = SDKFunction(
    description="OpenAI GPT Completion models (API).Automatically complete and generate text based on provided input.This model predicts and generates the next word or sentence given a partial text input.",
    requires_gpu=False,
)


class SelectedModel(str, Enum):
    GPT_3_5 = "gpt-3.5-turbo"
    GPT_3_5_16K = "gpt-3.5-turbo-16k"
    GPT_4 = "gpt-4"
    GPT_4_32K = "gpt-4-32k"


class Inputs(CoreModel):
    prompt: str = Field(..., description="Input prompt")


class Params(CoreModel):
    model: SelectedModel = Field(
        ..., description="Model variant to be used for completion"
    )
    system_prompt: Optional[str] = Field(
        default=None,
        description="System prompt for the model (used to instruct the model)",
    )
    api_key: str = Field(..., description="OpenAI API KEY")
    max_tokens: Optional[int] = Field(
        default=None, description="Maximum number of tokens generated by the model"
    )
    temperature: Optional[float] = Field(default=None, description="Model temperature")
    top_p: Optional[float] = Field(default=None, description="Model Top P")


class Outputs(CoreModel):
    completion_text: str = Field(..., description="Completion text")


@func.on_execute
async def main(inputs: Inputs, params: Params) -> Outputs:
    if params.system_prompt is None:
        messages = [
            {"role": "user", "content": inputs.prompt},
        ]
    else:
        messages = [
            {
                "role": "system",
                "content": params.system_prompt,
            },
            {"role": "user", "content": inputs.prompt},
        ]

    chat_completion = await openai.ChatCompletion.acreate(
        model=params.model,
        messages=messages,
        api_key=params.api_key,
        max_tokens=params.max_tokens,
        temperature=params.temperature,
        top_p=params.top_p,
    )

    completion: str = chat_completion.choices[0].message.content  # type: ignore

    return Outputs(completion_text=completion)
